## Magma 
### Training data:

Ablation study:  CC12M (Conceptual 12M) - Image Captioning

Training: 
- LAION (Schuhmann et al., 2021)
- Wikipedia Image-Text (Srinivasan et al., 2021)
- CC3M (Changpinyo et al.,2021b)
- Visual Genome (Krishna et al., 2016)
- Localized Narratives (Pont-Tuset et al., 2020)
- VQA (Antol et al., 2015)
- GQA (Hudson andManning, 2019)
- OKVQA (Marino et al., 2019),
- VizWiz (Gurari et al., 2018)
- Hateful Memes (Kiela
et al., 2020)
- CoCo Captions (Chen et al., 2015).

--> 25 million image-text pairs to train our final model

### Training ojbective:
- training objective is a captioning task