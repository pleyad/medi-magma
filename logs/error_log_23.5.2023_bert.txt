[2023-05-23 08:47:05,495] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5]}
[2023-05-23 08:47:05,495] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=6, node_rank=0
[2023-05-23 08:47:05,495] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5]})
[2023-05-23 08:47:05,495] [INFO] [launch.py:247:main] dist_world_size=6
[2023-05-23 08:47:05,496] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5
[2023-05-23 08:47:23,173] [INFO] [comm.py:622:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Loading medicalai/ClinicalBERT language model...
Loading medicalai/ClinicalBERT language model...
Loading medicalai/ClinicalBERT language model...
Loading medicalai/ClinicalBERT language model...
Loading medicalai/ClinicalBERT language model...
Loading medicalai/ClinicalBERT language model...
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 76664.30it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
Loaded train dataset with 1000 samples
Loaded eval dataset with 0 samples
Loaded train dataset with 1000 samples
Loaded eval dataset with 0 samples
[2023-05-23 08:48:07,790] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.2, git-hash=unknown, git-branch=unknown
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 214817.11it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 208216.04it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 228584.88it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 248463.01it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
loading dataset paths from /home/user/vbernhard/medi-magma/data: 1000it [00:00, 251306.41it/s]
loading dataset paths from /data/coco_data: 0it [00:00, ?it/s]
[2023-05-23 08:48:10,815] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-23 08:48:10,816] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-23 08:48:10,816] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-23 08:48:10,854] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-23 08:48:10,855] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-05-23 08:48:10,855] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2023-05-23 08:48:10,855] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2023-05-23 08:48:10,984] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-05-23 08:48:10,985] [INFO] [utils.py:789:see_memory_usage] MA 0.53 GB         Max_MA 0.95 GB         CA 0.98 GB         Max_CA 1 GB 
[2023-05-23 08:48:10,985] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.73 GB, percent = 15.7%
[2023-05-23 08:48:10,989] [INFO] [stage3.py:113:__init__] Reduce bucket size 500000000
[2023-05-23 08:48:10,989] [INFO] [stage3.py:114:__init__] Prefetch bucket size 50000000
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Using /home/user/vbernhard/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Emitting ninja build file /home/user/vbernhard/.cache/torch_extensions/py37_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5740399360656738 seconds
Loading extension module utils...
Time to load utils op: 0.6047706604003906 seconds
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.6045558452606201 seconds
Loading extension module utils...
Time to load utils op: 0.6053175926208496 seconds
Time to load utils op: 0.6046092510223389 seconds
Time to load utils op: 0.6050403118133545 seconds
[2023-05-23 08:48:27,460] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-05-23 08:48:27,461] [INFO] [utils.py:789:see_memory_usage] MA 0.53 GB         Max_MA 0.53 GB         CA 0.98 GB         Max_CA 1 GB 
[2023-05-23 08:48:27,462] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.79 GB, percent = 15.7%
Parameter Offload: Total persistent parameters: 1349904 in 354 params
[2023-05-23 08:48:27,699] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-05-23 08:48:27,700] [INFO] [utils.py:789:see_memory_usage] MA 0.09 GB         Max_MA 0.56 GB         CA 1.01 GB         Max_CA 1 GB 
[2023-05-23 08:48:27,701] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.8 GB, percent = 15.7%
[2023-05-23 08:48:27,790] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-05-23 08:48:27,791] [INFO] [utils.py:789:see_memory_usage] MA 0.09 GB         Max_MA 0.09 GB         CA 1.01 GB         Max_CA 1 GB 
[2023-05-23 08:48:27,791] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.8 GB, percent = 15.7%
[2023-05-23 08:48:28,356] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 2
[2023-05-23 08:48:28,357] [INFO] [utils.py:789:see_memory_usage] MA 0.09 GB         Max_MA 0.09 GB         CA 0.1 GB         Max_CA 1 GB 
[2023-05-23 08:48:28,357] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 20.12 GB, percent = 16.0%
[2023-05-23 08:48:28,450] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-05-23 08:48:28,450] [INFO] [utils.py:789:see_memory_usage] MA 0.09 GB         Max_MA 0.09 GB         CA 0.1 GB         Max_CA 0 GB 
[2023-05-23 08:48:28,451] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 20.12 GB, percent = 16.0%
[2023-05-23 08:48:28,546] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-05-23 08:48:28,547] [INFO] [utils.py:789:see_memory_usage] MA 0.26 GB         Max_MA 0.3 GB         CA 0.36 GB         Max_CA 0 GB 
[2023-05-23 08:48:28,547] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 20.14 GB, percent = 16.0%
[2023-05-23 08:48:28,641] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-05-23 08:48:28,641] [INFO] [utils.py:789:see_memory_usage] MA 0.26 GB         Max_MA 0.26 GB         CA 0.36 GB         Max_CA 0 GB 
[2023-05-23 08:48:28,642] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 20.12 GB, percent = 16.0%
[2023-05-23 08:48:28,798] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-05-23 08:48:28,799] [INFO] [utils.py:789:see_memory_usage] MA 0.6 GB         Max_MA 0.86 GB         CA 1.15 GB         Max_CA 1 GB 
[2023-05-23 08:48:28,799] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 20.12 GB, percent = 16.0%
[2023-05-23 08:48:28,799] [INFO] [stage3.py:392:_setup_for_real_optimizer] optimizer state initialized
Traceback (most recent call last):
  File "train.py", line 112, in <module>
    config_params=config.deepspeed_config_params,
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/__init__.py", line 175, in initialize
    config_class=config_class)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/engine.py", line 308, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/engine.py", line 1173, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/engine.py", line 1490, in _configure_zero_optimizer
    communication_data_type=self.communication_data_type)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/zero/stage3.py", line 322, in __init__
    self.create_reduce_and_remove_grad_hooks()
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/zero/stage3.py", line 1007, in create_reduce_and_remove_grad_hooks
    param.all_gather()
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 873, in all_gather
    return self._all_gather(param_list, async_op=async_op, hierarchy=hierarchy)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1072, in _all_gather
    ret_value = self._allgather_params(all_gather_list, hierarchy=hierarchy)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1355, in _allgather_params
    async_op=False)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/comm/comm.py", line 120, in log_wrapper
    return func(*args, **kwargs)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/comm/comm.py", line 229, in all_gather
    return cdb.all_gather(tensor_list=tensor_list, tensor=tensor, group=group, async_op=async_op)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/deepspeed/comm/torch.py", line 121, in all_gather
    return torch.distributed.all_gather(tensor_list=tensor_list, tensor=tensor, group=group, async_op=async_op)
  File "/home/user/vbernhard/medi-magma/magma_venv/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 2277, in all_gather
    work = group.allgather([tensor_list], [tensor])
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2023-05-23 08:48:30,631] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5836
[2023-05-23 08:48:34,923] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5837
[2023-05-23 08:48:34,923] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5838
[2023-05-23 08:48:39,253] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5839
[2023-05-23 08:48:43,542] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5840
[2023-05-23 08:48:47,872] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 5841
[2023-05-23 08:48:52,322] [ERROR] [launch.py:434:sigkill_handler] ['/home/user/vbernhard/medi-magma/magma_venv/bin/python3', '-u', 'train.py', '--local_rank=5', '--config', 'MAGMA_medi_clinicalbert.yml'] exits with return code = 1
